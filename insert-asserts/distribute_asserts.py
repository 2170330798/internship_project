import math
import requests
import json
import pandas as pd
import time

def send_request(url="", headers="", payload=""):
    try:
        # å‘é€PUTè¯·æ±‚
        response = requests.put(url, headers=headers, data=json.dumps(payload))
        
        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code == 200:
            print("èµ„äº§ä¿¡æ¯æ›´æ–°æˆåŠŸï¼")
            print("å“åº”å†…å®¹:", response.json())
        else:
            print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            print("å“åº”å†…å®¹:", response.text)
    
    except requests.exceptions.RequestException as e:
        print("è¯·æ±‚å‘ç”Ÿé”™è¯¯:", e)

def ensure_string(value):
    return str(value) if not isinstance(value, str) else value

def ensure_float(value):
    try:
        return float(value) if not isinstance(value, (float, int)) else float(value)
    except (ValueError, TypeError):
        raise ValueError(f"æ— æ³•å°†{value}è½¬æ¢ä¸ºæµ®ç‚¹æ•°")

def ensure_int(value):
     if pd.isna(value) or (isinstance(value, float) and math.isnan(value)):
        return 0  # æˆ–è€…è¿”å›ä¸€ä¸ªé»˜è®¤å€¼å¦‚ 0
     else:
        return int(value) if not isinstance(value, int) else value


def update_asset_allocation(asset_id="", employee_id="", warehouse_id="", remark=""):
    """
    æ›´æ–°èµ„äº§åˆ†é…ä¿¡æ¯
    
    å‚æ•°:
        asset_id (str): èµ„äº§ID
        employee_id (str): å‘˜å·¥ID
        warehouse_id (str): ä»“åº“ID
        remark (str): å¤‡æ³¨ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
    """
    # APIç«¯ç‚¹
    url = "https://devops-api.nullmax.net/asset/api/v1/fixed/transfer/reallocate"
    
    # è¯·æ±‚å¤´
    headers = {
        "Authorization": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NTIwMjg0NDksImlhdCI6MTc0OTM3NjQ0OSwiaXNzIjoi5ZSQ5L-K5ZacIiwicm9sZV9pZCI6IlI1NzIwMzc3NzcyMjE4NzgwOCIsInN1YiI6ImxvZ2luIiwidXNlcl9pZCI6IjQyNiIsIndhcmVob3VzZV9pZHMiOnsiVzU3MjAzNzcwMzA5NzM4NDk2IjoiVzU3MjAzNzcwMzA5NzM4NDk2In19.HN41JNNFTBZu0blroR8kkAjHjUTRMppZ611adaTQZ2A",
        "Content-Type": "application/json",
        "Origin": "https://devops.nullmax.net",
        "Referer": "https://devops.nullmax.net/",
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36",
        "Warehouse": "W57203770309738496",
        "Accept": "application/json, text/plain, */*",
        "Accept-Encoding": "gzip, deflate, br",
        "Accept-Language": "en-US,en;q=0.9"
    }
    
    # è¯·æ±‚ä½“
    payload = {
        "id": ensure_string(asset_id),
        "employeeId": ensure_string(ensure_int(employee_id)),
        "warehouseId": ensure_string(warehouse_id),
        "remark": ensure_string(remark)
    }
    print(payload)
    send_request(url=url, headers=headers, payload=payload)

def read_excel_sheet(file_path, sheet_name=None, columns=None, condition_column=None, condition_value=None):
    """
    è¯»å–Excelè¡¨æ ¼çš„æŒ‡å®šsheetå’Œåˆ—ï¼Œå¹¶å¯é€‰æ‹©æ ¹æ®æ¡ä»¶ç­›é€‰
    """
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        if sheet_name is not None and isinstance(df, dict):
            df = df[sheet_name]
        
        # ç­›é€‰æ¡ä»¶
        #if condition_column and condition_value:
        #    df = df[df[condition_column] == condition_value]
        # æ‰§è¡Œæœç´¢
        if condition_column and condition_value:
            df = df[df[condition_column].astype(str).str.contains(condition_value, case=False, na=False)]
    
        # é€‰æ‹©æŒ‡å®šåˆ—
        if columns:
            df = df[columns]
        
        return df
    except Exception as e:
        print(f"è¯»å–Excelæ–‡ä»¶å‡ºé”™: {e}")
        return None

def compare_and_merge(table1_path, table1_sheet, table1_columns, table1_status_column, table1_status_value,
                     table2_path, table2_sheet, table2_columns,
                     table3_path=None, table3_sheet=None, table3_columns=None,
                     output_path="output.xlsx"):
    """
    æ¯”è¾ƒå¹¶åˆå¹¶è¡¨æ ¼æ•°æ®
    """
    # è¯»å–è¡¨1
    table1 = read_excel_sheet(table1_path, table1_sheet, table1_columns, 
                             table1_status_column, table1_status_value)
    if table1 is None:
        return
    
    # è¯»å–è¡¨2
    table2 = read_excel_sheet(table2_path, table2_sheet, table2_columns)
    if table2 is None:
        return
    
    # è¯»å–è¡¨3ï¼ˆå¦‚æœæœ‰ï¼‰
    table3 = None
    if table3_path and table3_sheet and table3_columns:
        table3 = read_excel_sheet(table3_path, table3_sheet, table3_columns)
    
    # ç¡®ä¿è¡¨1æœ‰'ç¼–å·'åˆ—ï¼Œè¡¨2æœ‰'assetCode'åˆ—
    if 'ç¼–å·' not in table1.columns or 'assetCode' not in table2.columns:
        print("è¡¨1ç¼ºå°‘'ç¼–å·'åˆ—æˆ–è¡¨2ç¼ºå°‘'assetCode'åˆ—")
        return
    
    # æ¯”è¾ƒå¹¶åˆå¹¶è¡¨1å’Œè¡¨2
    # å°†æ¯”è¾ƒå­—æ®µè½¬ä¸ºå¤§å†™
    table1['ç¼–å·'] = table1['ç¼–å·'].astype(str).str.upper() 
    table2['assetCode'] = table2['assetCode'].astype(str).str.upper()
    
    # åˆå¹¶è¡¨1å’Œè¡¨2
    merged = pd.merge(table1, table2, 
                      left_on='ç¼–å·', 
                      right_on='assetCode',
                      how='inner')
    
    # é€‰æ‹©éœ€è¦çš„åˆ—
    result_columns = []
    if 'ä½¿ç”¨äºº (äººå‘˜ )' in merged.columns:
        result_columns.append('ä½¿ç”¨äºº (äººå‘˜ )')
    if 'id' in merged.columns:
        result_columns.append('id')
    if 'warehouseId' in merged.columns:
        result_columns.append('warehouseId')
    if 'ç¼–å·' in merged.columns:
        result_columns.append('ç¼–å·')
    
    if not result_columns:
        print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦çš„åˆ—")
        return
    
    result = merged[result_columns]
    
    # å¦‚æœæœ‰è¡¨3ï¼Œå¤„ç†å‘˜å·¥IDæ˜ å°„
    if table3 is not None and 'employeeName' in table3.columns and 'id' in table3.columns:
        # é‡å‘½åè¡¨3çš„idåˆ—ä¸ºemployeeIdï¼Œé¿å…ä¸è¡¨2çš„idåˆ—å†²çª
        table3 = table3.rename(columns={'id': 'employeeId'})
        
        # åˆå¹¶å‘˜å·¥IDä¿¡æ¯
        result = pd.merge(result, table3, 
                          left_on='ä½¿ç”¨äºº (äººå‘˜ )', 
                          right_on='employeeName',
                          how='left')
        
        # æ›¿æ¢ä½¿ç”¨äºº (äººå‘˜ 2)ä¸ºemployeeId
        result['employeeId'] = result['employeeId'].fillna(result['ä½¿ç”¨äºº (äººå‘˜ )'])
        result = result.drop(columns=['ä½¿ç”¨äºº (äººå‘˜ )', 'employeeName'], errors='ignore')
    
    # ä¿å­˜ç»“æœ
    try:
        result.to_excel(output_path, index=False)
        print(f"ç»“æœå·²ä¿å­˜åˆ° {output_path}")
    except Exception as e:
        print(f"ä¿å­˜ç»“æœå‡ºé”™: {e}")


def search_and_save_excel(input_file, output_file, search_column, keyword, 
                         sheet_name=None, is_save=False, skip_rows=0):
    """
    å¢å¼ºç‰ˆExcelæœç´¢å·¥å…·ï¼šè‡ªåŠ¨å¤„ç†æ··åˆæ—¥æœŸæ ¼å¼
    
    å‚æ•°:
        date_columns: éœ€è¦è½¬æ¢çš„æ—¥æœŸåˆ—ï¼ˆå¦‚["è´­å…¥æˆ–å…¥è´¦æ—¥æœŸ"]ï¼‰ï¼Œè‡ªåŠ¨å¤„ç†ä»¥ä¸‹æ ¼å¼ï¼š
                      - Excelåºåˆ—æ•°å­—ï¼ˆå¦‚43101ï¼‰
                      - å­—ç¬¦ä¸²æ—¥æœŸï¼ˆå¦‚"9/30/2018"ï¼‰
                      - ç©ºå€¼è‡ªåŠ¨è½¬ä¸ºNaT
        skip_rows: è·³è¿‡å‰é¢å¤šå°‘è¡Œæ— æ•ˆå€¼
    """
    
    try:
        xls = pd.ExcelFile(input_file)
        all_sheets = xls.sheet_names
        
        # å¤„ç†sheet_nameå‚æ•°
        if sheet_name is None:
            sheets_to_process = [all_sheets[0]]
        elif isinstance(sheet_name, (int, str)):
            sheets_to_process = [sheet_name]
        elif isinstance(sheet_name, list):
            sheets_to_process = sheet_name
        else:
            raise ValueError("sheet_nameå‚æ•°å¿…é¡»æ˜¯å·¥ä½œè¡¨åã€ç´¢å¼•ã€åˆ—è¡¨æˆ–None")
        
        all_matched_rows = []
        
        for sheet in sheets_to_process:
            try:
                # è¯»å–æ•°æ®ï¼ˆè·³è¿‡å‰ä¸¤è¡Œï¼‰
                df = pd.read_excel(input_file, sheet_name=sheet, header=skip_rows)
                print(f"\nå¤„ç†å·¥ä½œè¡¨: '{sheet}' (å…± {len(df)} è¡Œ)")
                
                # å¤„ç†æœç´¢åˆ—
                if isinstance(search_column, int):
                    if search_column >= len(df.columns):
                        print(f"è­¦å‘Š: åˆ—ç´¢å¼• {search_column} è¶…å‡ºèŒƒå›´")
                        continue
                    column = df.columns[search_column]
                else:
                    if search_column not in df.columns:
                        print(f"è­¦å‘Š: åˆ—å '{search_column}' ä¸å­˜åœ¨ï¼Œå¯ç”¨åˆ—: {list(df.columns)}")
                        continue
                    column = search_column
                
                # æ‰§è¡Œæœç´¢
                matched_rows = df[df[column].astype(str).str.contains(keyword, case=False, na=False)]
                
                if len(matched_rows) > 0:
                    print(f"âœ… æ‰¾åˆ° {len(matched_rows)} è¡ŒåŒ¹é…å†…å®¹")
                    matched_rows['æ¥æºå·¥ä½œè¡¨'] = sheet
                    all_matched_rows.append(matched_rows)
                
            except Exception as e:
                print(f"å¤„ç†å·¥ä½œè¡¨ '{sheet}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_matched_rows:
            print(f"\næœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„è¡Œ")
            return None
        
        final_result = pd.concat(all_matched_rows, ignore_index=True)
        
        # ä¿å­˜ç»“æœ
        if is_save:
            try:
                final_result.to_excel(output_file, index=False)
                print(f"\nğŸ’¾ å·²ä¿å­˜ {len(final_result)} è¡Œåˆ° {output_file}")
            except Exception as e:
                print(f"ä¿å­˜å¤±è´¥: {str(e)}")
        
        return final_result
    
    except Exception as e:
        print(f"å…¨å±€é”™è¯¯: {str(e)}")
        return None

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # # è¡¨1é…ç½®
    # table1_path = "/home/ubuntu/Downloads/assets_list.xlsx"
    # table1_sheet = "å…¶ä»–"  # æŒ‡å®šsheetåç§°æˆ–Noneä½¿ç”¨ç¬¬ä¸€ä¸ªsheet
    # table1_columns = ["ç¼–å·", "ä½¿ç”¨äºº (äººå‘˜ )", "è¯´æ˜"]  # è¦è¯»å–çš„åˆ—
    # table1_status_column = "è¯´æ˜"  # ç­›é€‰æ¡ä»¶çš„åˆ—
    # table1_status_value = "å…¶ä»–è®¾å¤‡"  # ç­›é€‰æ¡ä»¶çš„å€¼
    
    # # è¡¨2é…ç½®
    # table2_path = "/home/ubuntu/Downloads/orthers_info1.xlsx"
    # table2_sheet = "Sheet1"  # æŒ‡å®šsheetåç§°æˆ–Noneä½¿ç”¨ç¬¬ä¸€ä¸ªsheet
    # table2_columns = ["id", "warehouseId", "assetCode"]  # è¦è¯»å–çš„åˆ—
    
    # # è¡¨3é…ç½®ï¼ˆå¯é€‰ï¼‰
    # table3_path = "/home/ubuntu/Downloads/employee_info.xlsx"  # è®¾ä¸ºNoneå¦‚æœä¸ä½¿ç”¨è¡¨3
    # table3_sheet = "Sheet1"  # æŒ‡å®šsheetåç§°æˆ–Noneä½¿ç”¨ç¬¬ä¸€ä¸ªsheet
    # table3_columns = ["id", "employeeName"]  # è¦è¯»å–çš„åˆ—
    
    # # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    # output_path = "/home/ubuntu/Downloads/merge_info12.xlsx"
    
    # # æ‰§è¡Œæ¯”è¾ƒå’Œåˆå¹¶
    # compare_and_merge(
    #     table1_path, table1_sheet, table1_columns, table1_status_column, table1_status_value,
    #     table2_path, table2_sheet, table2_columns,
    #     table3_path, table3_sheet, table3_columns,
    #     output_path
    # )

    # è®¾ç½®å»¶è¿Ÿæ—¶é—´
    delay_time = 1
    # è®¾ç½®æ–‡ä»¶å‚æ•°
    input_excle_file_dir = "/home/ubuntu/Downloads"
    input_excle_file_name = "merge_info12.xlsx"
    # output_excel_file_dir = "/home/ubuntu/Downloads"  
    # output_excel_file_name = "low_network_switch.xlsx"
    column_to_search = 0           # å¯ä»¥æ˜¯åˆ—å(å¦‚"å§“å")æˆ–åˆ—ç´¢å¼•( ä»0å¼€å§‹)
    search_keyword = ""           # è¦æœç´¢çš„å…³é”®å­—
    sheet_name = "Sheet1"      # æŸ¥æ‰¾çš„è¡¨
    skip_rows = 0
    asset_data = search_and_save_excel(
        input_file=input_excle_file_dir+'/'+input_excle_file_name, 
        output_file=None, 
        search_column=column_to_search, 
        keyword=search_keyword,
        sheet_name=sheet_name, # å¯ä»¥ä¿®æ”¹ä¸ºä¸Šé¢æ³¨é‡Šä¸­çš„ä»»æ„ä¸€ç§å½¢å¼
        is_save=False,
        skip_rows = skip_rows
    )
    
    for index, row in asset_data.iterrows():
        print(f"èµ„äº§ID: {row['id']},  ä»“åº“ID: {row['warehouseId']},  ä½¿ç”¨äºº: {ensure_int(row['employeeId'])},  èµ„äº§ç¼–å·: {row['ç¼–å·']}")
        # æ›¿æ¢ä¸ºå®é™…çš„èµ„äº§IDã€å‘˜å·¥IDå’Œä»“åº“ID
        # asset_id = "AF57232242631508000"
        # employee_id = "454"
        # warehouse_id = "W57203770309738496"
        # remark = "èµ„äº§é‡æ–°åˆ†é…"
        update_asset_allocation(row['id'], row['employeeId'], row['warehouseId'], remark="")
        time.sleep(delay_time)  # ä¼‘çœ 1ç§’

