from datetime import datetime
import time
import requests
import json
import pandas as pd

def send_request(url=None, 
                 headers=None,
                 payload=None):
    try:
        # å‘é€POSTè¯·æ±‚
        response = requests.put(
            url,
            headers=headers,
            data=json.dumps(payload),  # å°†å­—å…¸è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            verify=True  # éªŒè¯SSLè¯ä¹¦
        )

        # æ‰“å°å“åº”ä¿¡æ¯
        print(f"Status Code: {response.status_code}")
        print("Response Headers:")
        for key, value in response.headers.items():
            print(f"{key}: {value}")
        
        print("\nResponse Body:")
        print(response.text)

        # å¦‚æœéœ€è¦å¤„ç†JSONå“åº”
        if "application/json" in response.headers.get("content-type", ""):
            response_json = response.json()
            print("\nJSON Response:")
            print(json.dumps(response_json, indent=2, ensure_ascii=False))

    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")

def search_and_save_excel(input_file, output_file, search_column, keyword, 
                         sheet_name=None, is_save=False, skip_rows=0,
                         format_column=None, uppercase=False):
    """
    å¢å¼ºç‰ˆExcelæœç´¢å·¥å…·ï¼šè‡ªåŠ¨å¤„ç†æ··åˆæ—¥æœŸæ ¼å¼
    
    å‚æ•°:
        input_file: è¾“å…¥Excelæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
        search_column: è¦æœç´¢çš„åˆ—(åˆ—åæˆ–åˆ—ç´¢å¼•)
        keyword: è¦æœç´¢çš„å…³é”®è¯
        sheet_name: è¦å¤„ç†çš„å·¥ä½œè¡¨å(å¯ä»¥æ˜¯å•ä¸ªåç§°ã€ç´¢å¼•ã€åˆ—è¡¨æˆ–None)
        is_save: æ˜¯å¦ä¿å­˜ç»“æœ
        skip_rows: è·³è¿‡çš„è¡Œæ•°
        format_column: éœ€è¦æ ¼å¼åŒ–çš„åˆ—(åˆ—åæˆ–åˆ—ç´¢å¼•)
        uppercase: æ˜¯å¦å°†format_columnåˆ—çš„å†…å®¹è½¬ä¸ºå¤§å†™
        
    date_columns: éœ€è¦è½¬æ¢çš„æ—¥æœŸåˆ—ï¼ˆå¦‚["è´­å…¥æˆ–å…¥è´¦æ—¥æœŸ"]ï¼‰ï¼Œè‡ªåŠ¨å¤„ç†ä»¥ä¸‹æ ¼å¼ï¼š
                  - Excelåºåˆ—æ•°å­—ï¼ˆå¦‚43101ï¼‰
                  - å­—ç¬¦ä¸²æ—¥æœŸï¼ˆå¦‚"9/30/2018"ï¼‰
                  - ç©ºå€¼è‡ªåŠ¨è½¬ä¸ºNaT
    """
    try:
        xls = pd.ExcelFile(input_file)
        all_sheets = xls.sheet_names
        
        # å¤„ç†sheet_nameå‚æ•°
        if sheet_name is None:
            sheets_to_process = [all_sheets[0]]
        elif isinstance(sheet_name, (int, str)):
            sheets_to_process = [sheet_name]
        elif isinstance(sheet_name, list):
            sheets_to_process = sheet_name
        else:
            raise ValueError("sheet_nameå‚æ•°å¿…é¡»æ˜¯å·¥ä½œè¡¨åã€ç´¢å¼•ã€åˆ—è¡¨æˆ–None")
        
        all_matched_rows = []
        
        for sheet in sheets_to_process:
            try:
                # è¯»å–æ•°æ®ï¼ˆè·³è¿‡å‰ä¸¤è¡Œï¼‰
                df = pd.read_excel(input_file, sheet_name=sheet, header=skip_rows)
                print(f"\nå¤„ç†å·¥ä½œè¡¨: '{sheet}' (å…± {len(df)} è¡Œ)")
                
                # å¤„ç†æœç´¢åˆ—
                if isinstance(search_column, int):
                    if search_column >= len(df.columns):
                        print(f"è­¦å‘Š: åˆ—ç´¢å¼• {search_column} è¶…å‡ºèŒƒå›´")
                        continue
                    column = df.columns[search_column]
                else:
                    if search_column not in df.columns:
                        print(f"è­¦å‘Š: åˆ—å '{search_column}' ä¸å­˜åœ¨ï¼Œå¯ç”¨åˆ—: {list(df.columns)}")
                        continue
                    column = search_column
                
                # æ‰§è¡Œæœç´¢
                matched_rows = df[df[column].astype(str).str.contains(keyword, case=False, na=False)]
                
                # å¤„ç†æ ¼å¼åŒ–åˆ—
                if format_column is not None and len(matched_rows) > 0:
                    if isinstance(format_column, int):
                        if format_column >= len(matched_rows.columns):
                            print(f"è­¦å‘Š: æ ¼å¼åŒ–åˆ—ç´¢å¼• {format_column} è¶…å‡ºèŒƒå›´")
                        else:
                            format_col_name = matched_rows.columns[format_column]
                    else:
                        if format_column not in matched_rows.columns:
                            print(f"è­¦å‘Š: æ ¼å¼åŒ–åˆ—å '{format_column}' ä¸å­˜åœ¨")
                        else:
                            format_col_name = format_column
                    
                    if 'format_col_name' in locals():
                        if uppercase:
                            matched_rows[format_col_name] = matched_rows[format_col_name].astype(str).str.upper()
                            print(f"å·²å°†åˆ— '{format_col_name}' å†…å®¹è½¬ä¸ºå¤§å†™")
                
                if len(matched_rows) > 0:
                    print(f"âœ… æ‰¾åˆ° {len(matched_rows)} è¡ŒåŒ¹é…å†…å®¹")
                    matched_rows['æ¥æºå·¥ä½œè¡¨'] = sheet
                    all_matched_rows.append(matched_rows)
                
            except Exception as e:
                print(f"å¤„ç†å·¥ä½œè¡¨ '{sheet}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_matched_rows:
            print(f"\næœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„è¡Œ")
            return None
        
        final_result = pd.concat(all_matched_rows, ignore_index=True)
        
        # ä¿å­˜ç»“æœ
        if is_save:
            try:
                final_result.to_excel(output_file, index=False)
                print(f"\nğŸ’¾ å·²ä¿å­˜ {len(final_result)} è¡Œåˆ° {output_file}")
            except Exception as e:
                print(f"ä¿å­˜å¤±è´¥: {str(e)}")
        
        return final_result
    
    except Exception as e:
        print(f"å…¨å±€é”™è¯¯: {str(e)}")
        return None

def convert_date_to_short_string(date):
    """
    å°† row["è´­å…¥æˆ–å…¥è´¦æ—¥æœŸ"] ä» "2025-05-30 00:00:00" è½¬ä¸º "2025-05-30"
    
    å‚æ•°:
        row: pandas DataFrame çš„æŸä¸€è¡Œï¼ˆåŒ…å«æ—¥æœŸåˆ—ï¼‰
    
    è¿”å›:
        str: æ ¼å¼åŒ–åçš„æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆå¦‚ "2025-05-30"ï¼‰
    """
    if pd.isna(date):
        return ""  # å¤„ç†ç©ºå€¼
    
    # å¦‚æœå·²ç»æ˜¯ datetime å¯¹è±¡ï¼Œç›´æ¥æ ¼å¼åŒ–
    if isinstance(date, (pd.Timestamp, datetime)):
        return date.strftime("%Y-%m-%d")
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆè½¬ä¸º datetime å†æ ¼å¼åŒ–
    try:
        date_obj = datetime.strptime(date, "%Y-%m-%d %H:%M:%S")
        return date_obj.strftime("%Y-%m-%d")
    except ValueError:
        return "0000-00-00"  # å¦‚æœæ ¼å¼ä¸ç¬¦ï¼Œè¿”å›0000-00-00

def ensure_float(value):
    try:
        return float(value) if not isinstance(value, (float, int)) else float(value)
    except (ValueError, TypeError):
        raise ValueError(f"æ— æ³•å°†{value}è½¬æ¢ä¸ºæµ®ç‚¹æ•°")

def ensure_int(value):
    return int(value) if not isinstance(value, int) else value

def ensure_string(value, is_upper = False):
    if is_upper:
        return str(value).upper() if not isinstance(value, str) else value.upper()
    else :
        return str(value) if not isinstance(value, str) else value

def convert_date(date_str):
    if pd.isna(date_str) or date_str is None or date_str == "" or len(date_str) < 8:
        return "0000-00-00"  # æˆ–è€…è¿”å› None æˆ–å…¶ä»–é»˜è®¤å€¼
    # è§£æå‰8ä½å­—ç¬¦ä¸ºæ—¥æœŸ
    date_obj = datetime.strptime(date_str[:8], "%Y%m%d").date()
    formatted_date = date_obj.strftime("%Y-%m-%d")
    #print(formatted_date)  # è¾“å‡º: 2023-08-01
    return formatted_date

def set_payload(asset_amount = 0.0, #å•ä»·
                asset_code = "",  #èµ„äº§ç¼–å·
                asset_name = "",  #èµ„äº§åç§°
                asset_type = 0,  #èµ„äº§æ¥æº
                category_id = "", #èµ„äº§ç±»åˆ«ID
                asset_id = "",
                purchase_date = "", #èµ„äº§è´­å…¥/ç§Ÿèµæ—¥æœŸ
                serial_number = "", #èµ„äº§åºåˆ—å·
                specifications = "", #èµ„äº§å‹å·
                warehouse_id = "", #ä»“åº“ID
                warranty_period_date = "", #è´¨ä¿æœŸ
                remark = "" #å¤‡æ³¨
    ):
    
    # è¯·æ±‚ä½“æ•°æ®
    payload = {
        "id": ensure_string(asset_id),
        "warehouseId": ensure_string(warehouse_id),
        "categoryId": ensure_string(category_id),
        "amount": ensure_float(asset_amount),
        "assetCode": ensure_string(asset_code),
        "assetImages": [],
        "assetName":  ensure_string(asset_name),
        "assetType": ensure_int(asset_type),
        "contact": "",
        "contactInfo": "",
        "purchaseDate": convert_date(ensure_string(purchase_date)),
        "remark": ensure_string(remark),
        "serialNumber": ensure_string(serial_number),
        "specifications": ensure_string(specifications),
        "supplierName": "",
        "warrantyPeriodDate": ensure_string(warranty_period_date)
    }


    return payload



import pandas as pd

def read_excel_sheet(file_path, sheet_name=None, columns=None):
    """
    è¯»å–Excelæ–‡ä»¶çš„æŒ‡å®šsheetå’Œåˆ—
    :param file_path: Excelæ–‡ä»¶è·¯å¾„
    :param sheet_name: sheetåç§°ï¼Œå¦‚æœä¸ºNoneåˆ™è¯»å–ç¬¬ä¸€ä¸ªsheet
    :param columns: è¦è¯»å–çš„åˆ—ï¼Œå¦‚æœä¸ºNoneåˆ™è¯»å–æ‰€æœ‰åˆ—
    :return: DataFrame
    """
    if sheet_name is None:
        return pd.read_excel(file_path, usecols=columns)
    else:
        return pd.read_excel(file_path, sheet_name=sheet_name, usecols=columns)

def compare_and_save(file1_path, file1_sheet, file1_columns,
                     file2_path, file2_sheet, file2_columns,
                     compare_field1, compare_field2,
                     output_path):
    """
    æ¯”è¾ƒä¸¤ä¸ªExcelæ–‡ä»¶çš„æŒ‡å®šå­—æ®µå¹¶ä¿å­˜åŒ¹é…ç»“æœ
    :param file1_path: ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶è·¯å¾„
    :param file1_sheet: ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶çš„sheetåç§°
    :param file1_columns: ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶è¦è¯»å–çš„åˆ—
    :param file2_path: ç¬¬äºŒä¸ªExcelæ–‡ä»¶è·¯å¾„
    :param file2_sheet: ç¬¬äºŒä¸ªExcelæ–‡ä»¶çš„sheetåç§°
    :param file2_columns: ç¬¬äºŒä¸ªExcelæ–‡ä»¶è¦è¯»å–çš„åˆ—
    :param compare_field1: ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶ç”¨äºæ¯”è¾ƒçš„å­—æ®µå
    :param compare_field2: ç¬¬äºŒä¸ªExcelæ–‡ä»¶ç”¨äºæ¯”è¾ƒçš„å­—æ®µå
    :param output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # è¯»å–ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶
    df1 = read_excel_sheet(file1_path, file1_sheet, file1_columns)
    # è¯»å–ç¬¬äºŒä¸ªExcelæ–‡ä»¶
    df2 = read_excel_sheet(file2_path, file2_sheet, file2_columns)
    
    # å°†æ¯”è¾ƒå­—æ®µè½¬æ¢ä¸ºå¤§å†™
    df1[compare_field1] = df1[compare_field1].astype(str).str.upper()
    df2[compare_field2] = df2[compare_field2].astype(str).str.upper()
    
    # åˆå¹¶ä¸¤ä¸ªDataFrameï¼ŒåŸºäºæ¯”è¾ƒå­—æ®µ
    merged_df = pd.merge(df1, df2, left_on=compare_field1, right_on=compare_field2, how='inner')
    
    # é€‰æ‹©è¦ä¿å­˜çš„åˆ—
    # è¡¨1çš„å­—æ®µï¼šç¼–å·(æ¯”è¾ƒå­—æ®µ)ã€èµ„äº§å‹å·åç§°ã€éªŒæ”¶ç¼–å·ã€åºåˆ—å·
    # è¡¨2çš„å­—æ®µï¼šidã€warehouseId
    # ç¡®ä¿è¿™äº›å­—æ®µéƒ½å­˜åœ¨
    required_columns = [
        compare_field1,  # è¡¨1çš„ç¼–å·
        'èµ„äº§å‹å·åç§°', 'éªŒæ”¶ç¼–å·', 'åºåˆ—å·',  # è¡¨1çš„å…¶ä»–å­—æ®µ
        'id', 'warehouseId'  # è¡¨2çš„å­—æ®µ
    ]
    
    # æ£€æŸ¥merged_dfä¸­æ˜¯å¦æœ‰æ‰€éœ€çš„åˆ—
    available_columns = [col for col in required_columns if col in merged_df.columns]
    
    if not available_columns:
        print("é”™è¯¯ï¼šåˆå¹¶åçš„DataFrameä¸­æ²¡æœ‰æ‰€éœ€çš„åˆ—")
        return
    
    # ä¿å­˜åˆ°æ–°çš„Excelæ–‡ä»¶
    merged_df[available_columns].to_excel(output_path, index=False)
    print(f"åŒ¹é…ç»“æœå·²ä¿å­˜åˆ°: {output_path}")




if __name__ == "__main__":

    # è´­å…¥
    PURCHASE = 1
    # ç§Ÿèµ
    RENT = 2
    # èµ é€
    DONATE = 3
    # è®¾ç½®æ¥æº
    WAY = PURCHASE
    
    # è®¾ç½®å¼€å¤´æ— æ•ˆæ•°æ®è¡Œæ•°
    skip_rows = 0
    # è®¾ç½®å‘é€é—´éš”æ—¶é—´
    delay_time = 1 # 1s
    # è®¾ç½®æ–‡ä»¶å‚æ•°
    input_excle_file_dir = "/home/ubuntu/Downloads"
    input_excle_file_name = "assets_list.xlsx"
    output_excel_file_dir = "/home/ubuntu/Downloads"  
    output_excel_file_name = "zj_info.xlsx"
    column_to_search = 0             # å¯ä»¥æ˜¯åˆ—å(å¦‚"å§“å")æˆ–åˆ—ç´¢å¼•(ä»0å¼€å§‹ï¼‰
    search_keyword = ""           # è¦æœç´¢çš„å…³é”®å­—
    sheet_name = "ä¸»æœº"      # æŸ¥æ‰¾çš„è¡¨

    # è®¾ç½®è¯·æ±‚URL
    url = "https://devops-api.nullmax.net/asset/api/v1/fixed"

    # è®¾ç½®è¯·æ±‚å¤´
    
    headers = {
        "authority": "devops-api.nullmax.net",
        "accept": "application/json, text/plain, */*",
        "accept-language": "en-US,en;q=0.9",
        "authorization": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NTE3MTI1ODUsImlhdCI6MTc0OTA2MDU4NSwiaXNzIjoi5ZSQ5L-K5ZacIiwicm9sZV9pZCI6IlI1NzIwMzc3NzcyMjE4NzgwOCIsInN1YiI6ImxvZ2luIiwidXNlcl9pZCI6IjQyNiIsIndhcmVob3VzZV9pZHMiOnsiVzU3MjAzNzcwMzA5NzM4NDk2IjoiVzU3MjAzNzcwMzA5NzM4NDk2In19.jmHb1DCQR0e_EVgpC4uQvJHIqH3vPe1LaoWMDFTzhWw",
        "content-type": "application/json",
        "origin": "https://devops.nullmax.net",
        "referer": "https://devops.nullmax.net/",
        "sec-ch-ua": '"Google Chrome";v="95", "Chromium";v="95", ";Not A Brand";v="99"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Linux"',
        "sec-fetch-dest": "empty",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "same-site",
        "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36",
        "warehouse": "W57203770309738496"
    }

    
    '''
    "categoryId": ç±»åˆ«ID
        "C57228951773609984" --> ç¬”è®°æœ¬
        "C57228952616271872" --> ä¸»æœº
        "C57231373712162816" --> æ˜¾ç¤ºå™¨
        "C57228956114354176" --> ç§»åŠ¨ç¡¬ç›˜
        "C57228956763357184" --> åŠå…¬ç½‘ç»œè®¾å¤‡
        "C57229182348394496" --> åŠå…¬å…¶ä»–è®¾å¤‡
        ...
    '''

    # # é…ç½®å‚æ•°
    # file1_path = '/home/ubuntu/Downloads/assets_list.xlsx'  # ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶è·¯å¾„
    # file1_sheet = 'ç¬”è®°æœ¬'  # ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶çš„sheetåç§°
    # file1_columns = ['ç¼–å·', 'èµ„äº§å‹å·åç§°', 'éªŒæ”¶ç¼–å·', 'åºåˆ—å·']  # ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶è¦è¯»å–çš„åˆ—
    
    # file2_path = '/home/ubuntu/Downloads/bjb_info.xlsx'  # ç¬¬äºŒä¸ªExcelæ–‡ä»¶è·¯å¾„
    # file2_sheet = 'Sheet1'  # ç¬¬äºŒä¸ªExcelæ–‡ä»¶çš„sheetåç§°
    # file2_columns = ['id', 'warehouseId', 'assetCode']  # ç¬¬äºŒä¸ªExcelæ–‡ä»¶è¦è¯»å–çš„åˆ—
    
    # compare_field1 = 'ç¼–å·'  # ç¬¬ä¸€ä¸ªExcelæ–‡ä»¶ç”¨äºæ¯”è¾ƒçš„å­—æ®µå
    # compare_field2 = 'assetCode'  # ç¬¬äºŒä¸ªExcelæ–‡ä»¶ç”¨äºæ¯”è¾ƒçš„å­—æ®µå
    
    # output_path = '/home/ubuntu/Downloads/merge_info7.xlsx'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    
    # # æ‰§è¡Œæ¯”è¾ƒå’Œä¿å­˜
    # compare_and_save(file1_path, file1_sheet, file1_columns,
    #                 file2_path, file2_sheet, file2_columns,
    #                 compare_field1, compare_field2,
    #                 output_path)




    
    # æŒ‡å®šè¦æœç´¢çš„å·¥ä½œè¡¨(å¯é€‰):
    # sheet_to_search = None       # æœç´¢ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨(é»˜è®¤)
    # sheet_to_search = "Sheet1"   # æœç´¢æŒ‡å®šåç§°çš„å·¥ä½œè¡¨
    # sheet_to_search = 1          # æœç´¢ç¬¬äºŒä¸ªå·¥ä½œè¡¨(ç´¢å¼•ä»0å¼€å§‹)
    # sheet_to_search = ["Sheet1", "Sheet2"]  # æœç´¢å¤šä¸ªå·¥ä½œè¡¨
    asset_data = search_and_save_excel(
        input_file=input_excle_file_dir+'/'+input_excle_file_name, 
        output_file=output_excel_file_dir+'/'+output_excel_file_name, 
        search_column=column_to_search, 
        keyword=search_keyword,
        sheet_name=sheet_name, # å¯ä»¥ä¿®æ”¹ä¸ºä¸Šé¢æ³¨é‡Šä¸­çš„ä»»æ„ä¸€ç§å½¢å¼
        is_save=False,
        skip_rows=skip_rows,
        format_column=None, 
        uppercase=False
    )

    for index, row in asset_data.iterrows():
        # è´­å…¥
        if WAY == PURCHASE:
            print(f"èµ„äº§ç¼–å·: {str(row['ä¸»æœºç¼–å·']).upper()}, ä½¿ç”¨çŠ¶æ€: {str(row['ä½¿ç”¨çŠ¶æ€'])}, ä½¿ç”¨äºº: {str(row['ä½¿ç”¨äºº (äººå‘˜ )'])}")
            #print(f"èµ„äº§ç¼–å·: {row['ç¼–å·']},	èµ„äº§åç§°: {row['èµ„äº§å‹å·åç§°']}, è´­å…¥æˆ–å…¥è´¦æ—¥æœŸ: {convert_date(ensure_string(row['éªŒæ”¶ç¼–å·']))}, S/Nç : {row['åºåˆ—å·']}, èµ„äº§ID: {row['id']}, ä»“åº“ID:{row['warehouseId']}")
            #print(f"èµ„äº§åç§°: {row['èµ„äº§å‹å·åç§°']},  å‹å·: {row['èµ„äº§å‹å·åç§°']}, S/Nç : {row['åºåˆ—å·']}  è´­å…¥æˆ–å…¥è´¦æ—¥æœŸ: {convert_date(ensure_string(row['éªŒæ”¶ç¼–å·']))}, èµ„äº§ç¼–å·: {ensure_string(row['ç¼–å·'], True)}")
            payload = set_payload(asset_amount = 0.0, 
                                  asset_code = row['ç¼–å·'], 
                                  asset_name = row['èµ„äº§å‹å·åç§°'], 
                                  asset_type = 1, 
                                  category_id = "C57228951773609984",
                                  asset_id= row['id'], 
                                  purchase_date = row['éªŒæ”¶ç¼–å·'], 
                                  serial_number = row['åºåˆ—å·'], 
                                  specifications = row['èµ„äº§å‹å·åç§°'], 
                                  warehouse_id = "W57203770309738496", 
                                  warranty_period_date = "",
                                  remark= "")
        elif WAY == RENT:
             # ç§Ÿèµ
            print(f"èµ„äº§åç§°: {row['èµ„äº§åç§°']},  å‹å·: {row['å‹å·']},  ç§Ÿèµæ—¥æœŸ: {row['ç§Ÿèµæ—¥æœŸ']}, S/Nå·: {row['S/Nå·']}, èµ„äº§ç¼–å·: {row['èµ„äº§ç¼–å·']}")
            payload = set_payload(asset_amount = 0.0, 
                                  asset_code = row['èµ„äº§ç¼–å·'], 
                                  asset_name = row['èµ„äº§åç§°'], 
                                  asset_type = 2, 
                                  category_id = "C57229559082188800", 
                                  purchase_date = row['ç§Ÿèµæ—¥æœŸ'], 
                                  serial_number = row['S/Nå·'], 
                                  specifications = row['å‹å·'],
                                  warehouse_id = "W57203770309738496", 
                                  warranty_period_date = "",
                                  remark="")
        elif WAY == DONATE:
            # æèµ 
            print(f"èµ„äº§åç§°: {row['èµ„äº§åç§°']},  å‹å·: {row['å‹å·']},  è´­å…¥æˆ–å…¥è´¦æ—¥æœŸ: {row['ç™»é™†æ—¥æœŸ']}, S/Nå·: {ensure_string(row['S/Nå·'])}, èµ„äº§ç¼–å·: {row['èµ„äº§ç¼–å·']}")
            payload = set_payload(asset_amount = 0.0, 
                                  asset_code = row['èµ„äº§ç¼–å·'], 
                                  asset_name = row['èµ„äº§åç§°'], 
                                  asset_type = 3, 
                                  category_id = "C57229558494593024", 
                                  purchase_date = row['ç™»é™†æ—¥æœŸ'], 
                                  serial_number = row['S/Nå·'], 
                                  specifications = row['å‹å·'], 
                                  warehouse_id = "W57203770309738496", 
                                  warranty_period_date = "",
                                  remark="å²©å±±èµ ä¸")
        # print(payload)
        # send_request(url, headers, payload)
        # time.sleep(delay_time)  # ä¼‘çœ 1ç§’
        


